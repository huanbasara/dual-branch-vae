{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "CODE_FOLDER = 'code'\n",
        "DATA_FOLDER = 'data'\n",
        "TEST_FOLDER = 'test'\n",
        "PROJECT_DIR = '/content/drive/MyDrive/Text2SVG'\n",
        "CODE_PATH = f\"{PROJECT_DIR}/{CODE_FOLDER}\"\n",
        "DATA_PATH = f\"{PROJECT_DIR}/{DATA_FOLDER}\"\n",
        "TEST_PATH = f\"{PROJECT_DIR}/{TEST_FOLDER}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Clone Code Repository\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Google Drive Dataset: Save samples as SVG and PNG files (Fixed coordinates)\n",
        "import torch\n",
        "import yaml\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "print(\"💾 Saving Google Drive Dataset samples with corrected coordinates...\")\n",
        "\n",
        "try:\n",
        "    # Load VAE config independently\n",
        "    from models.config import _DefaultConfig\n",
        "    from data.my_svg_dataset_pts import SVGDataset_GoogleDrive, Normalize\n",
        "    from utils.test_utils import pts_to_pathObj, save_paths_svg\n",
        "    import pydiffvg_lite as pydiffvg\n",
        "    \n",
        "    cfg = _DefaultConfig()\n",
        "    yaml_path = f'{CODE_PATH}/configs/vae_config_cmd_10.yaml'\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        config_data = yaml.safe_load(f)\n",
        "    for key, value in config_data.items():\n",
        "        setattr(cfg, key, value)\n",
        "    cfg.img_latent_dim = int(cfg.d_img_model / 64.0)\n",
        "    cfg.vq_edim = int(cfg.dim_z / cfg.vq_comb_num)\n",
        "    \n",
        "    print(f\"✅ Config loaded:\")\n",
        "    print(f\"   - use_model_fusion: {cfg.use_model_fusion}\")\n",
        "    print(f\"   - max_pts_len_thresh: {cfg.max_pts_len_thresh}\")\n",
        "    print(f\"   - img_size: {cfg.img_size}\")\n",
        "    \n",
        "    # Create Google Drive dataset for aardvark category\n",
        "    gdrive_dataset = SVGDataset_GoogleDrive(\n",
        "        data_path=DATA_PATH,\n",
        "        h=224, w=224,\n",
        "        fixed_length=cfg.max_pts_len_thresh,\n",
        "        category=\"aardvark\",\n",
        "        file_list=[\"66543-200.svg\"],\n",
        "        transform=Normalize(224, 224),\n",
        "        use_model_fusion=cfg.use_model_fusion\n",
        "    )\n",
        "    \n",
        "    print(f\"✅ Google Drive Dataset created: {len(gdrive_dataset)} path samples\")\n",
        "    \n",
        "    # Create normalizer for coordinate transformation\n",
        "    normalizer = Normalize(224, 224)\n",
        "    \n",
        "    # Create test directory\n",
        "    os.makedirs(TEST_PATH, exist_ok=True)\n",
        "    \n",
        "    if len(gdrive_dataset) > 0:\n",
        "        print(f\"\\n💾 Saving {len(gdrive_dataset)} samples to {TEST_PATH}\")\n",
        "        \n",
        "        for i in range(len(gdrive_dataset)):\n",
        "            sample = gdrive_dataset[i]\n",
        "            \n",
        "            # Get sample info\n",
        "            svg_path = sample[\"filepaths\"]\n",
        "            path_idx = sample[\"path_index\"]\n",
        "            normalized_points = sample[\"points\"]  # These are normalized (0-1 range)\n",
        "            cubics = sample[\"cubics\"]\n",
        "            path_img = sample[\"path_img\"]\n",
        "            \n",
        "            print(f\"\\n📄 Processing sample {i+1}:\")\n",
        "            print(f\"   Source: {os.path.basename(svg_path)}, path {path_idx}\")\n",
        "            print(f\"   Normalized points: {normalized_points.shape}\")\n",
        "            print(f\"   Coordinate range: x[{normalized_points[:, 0].min():.3f}, {normalized_points[:, 0].max():.3f}], y[{normalized_points[:, 1].min():.3f}, {normalized_points[:, 1].max():.3f}]\")\n",
        "            \n",
        "            # 🔧 CRITICAL FIX: Apply inverse transform to get pixel coordinates\n",
        "            denormalized_points = normalizer.inverse_transform(normalized_points)\n",
        "            print(f\"   Denormalized points: {denormalized_points.shape}\")\n",
        "            print(f\"   Pixel coordinates: x[{denormalized_points[:, 0].min():.1f}, {denormalized_points[:, 0].max():.1f}], y[{denormalized_points[:, 1].min():.1f}, {denormalized_points[:, 1].max():.1f}]\")\n",
        "            \n",
        "            # 1. Save reconstructed SVG from coordinates\n",
        "            try:\n",
        "                # Use denormalized points for SVG creation\n",
        "                path_obj = pts_to_pathObj(denormalized_points)\n",
        "                \n",
        "                # Create colors for the SVG\n",
        "                device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "                fill_color = torch.tensor([0.2, 0.2, 0.8, 1.0], device=device)  # Blue fill\n",
        "                stroke_color = torch.tensor([0.0, 0.0, 0.0, 1.0], device=device)  # Black stroke\n",
        "                \n",
        "                # Save as SVG file\n",
        "                svg_output_path = f\"{TEST_PATH}/sample_{i+1}_path_{path_idx}_fixed.svg\"\n",
        "                save_paths_svg(\n",
        "                    path_list=[path_obj],\n",
        "                    fill_color_list=[fill_color],\n",
        "                    stroke_width_list=[torch.tensor(2.0)],\n",
        "                    stroke_color_list=[stroke_color],\n",
        "                    svg_path_fp=svg_output_path,\n",
        "                    canvas_height=224,\n",
        "                    canvas_width=224\n",
        "                )\n",
        "                \n",
        "                print(f\"   📁 SVG saved: {os.path.basename(svg_output_path)}\")\n",
        "                \n",
        "                # Show first few coordinates in the generated SVG\n",
        "                with open(svg_output_path, 'r') as f:\n",
        "                    svg_content = f.read()\n",
        "                path_start = svg_content.find('d=\"') + 3\n",
        "                path_end = svg_content.find('\"', path_start)\n",
        "                path_data = svg_content[path_start:path_end]\n",
        "                print(f\"   📝 Generated SVG path (first 80 chars): {path_data[:80]}...\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"   ❌ SVG save failed: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "            \n",
        "            # 2. Save rendered image\n",
        "            try:\n",
        "                if len(path_img) > 0 and path_img.numel() > 0:\n",
        "                    # Convert tensor to PIL Image\n",
        "                    if path_img.dim() == 3:  # HWC format\n",
        "                        img_array = path_img.numpy()\n",
        "                        if img_array.shape[2] == 3:  # RGB\n",
        "                            # Normalize to 0-255 range\n",
        "                            img_array = (img_array * 255).clip(0, 255).astype('uint8')\n",
        "                            img_pil = Image.fromarray(img_array)\n",
        "                        else:  # Single channel\n",
        "                            img_array = (img_array[:,:,0] * 255).clip(0, 255).astype('uint8')\n",
        "                            img_pil = Image.fromarray(img_array, mode='L')\n",
        "                    else:\n",
        "                        # Handle other tensor formats\n",
        "                        img_array = (path_img.squeeze().numpy() * 255).clip(0, 255).astype('uint8')\n",
        "                        img_pil = Image.fromarray(img_array)\n",
        "                    \n",
        "                    # Save PNG file\n",
        "                    png_output_path = f\"{TEST_PATH}/sample_{i+1}_path_{path_idx}_fixed.png\"\n",
        "                    img_pil.save(png_output_path)\n",
        "                    \n",
        "                    print(f\"   📁 PNG saved: {os.path.basename(png_output_path)} ({img_pil.size})\")\n",
        "                    \n",
        "                else:\n",
        "                    print(f\"   ⚠️  No image data available (use_model_fusion=False)\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"   ❌ PNG save failed: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "        \n",
        "        print(f\"\\n✅ All samples saved to: {TEST_PATH}\")\n",
        "        print(f\"📊 Output files:\")\n",
        "        \n",
        "        # List saved files\n",
        "        saved_files = [f for f in os.listdir(TEST_PATH) if f.startswith('sample_') and 'fixed' in f]\n",
        "        for f in sorted(saved_files):\n",
        "            print(f\"   📄 {f}\")\n",
        "            \n",
        "    else:\n",
        "        print(\"❌ No samples found in dataset\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Sample saving failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install torch torchvision numpy scipy pandas scikit-learn matplotlib pillow svglib svgpathtools\n",
        "%pip install kornia opencv-python cairosvg pyyaml easydict tqdm\n",
        "# Install additional packages for SVG rendering support\n",
        "%pip install svglib reportlab cssutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Google Drive Dataset: Save samples as SVG and PNG files (Fixed coordinates and consistency)\n",
        "import torch\n",
        "import yaml\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "print(\"💾 Saving Google Drive Dataset samples with corrected coordinates and consistent rendering...\")\n",
        "\n",
        "try:\n",
        "    # Load VAE config independently\n",
        "    from models.config import _DefaultConfig\n",
        "    from data.my_svg_dataset_pts import SVGDataset_GoogleDrive, Normalize\n",
        "    from utils.test_utils import pts_to_pathObj, save_paths_svg\n",
        "    import pydiffvg_lite as pydiffvg\n",
        "    \n",
        "    cfg = _DefaultConfig()\n",
        "    yaml_path = f'{CODE_PATH}/configs/vae_config_cmd_10.yaml'\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        config_data = yaml.safe_load(f)\n",
        "    for key, value in config_data.items():\n",
        "        setattr(cfg, key, value)\n",
        "    cfg.img_latent_dim = int(cfg.d_img_model / 64.0)\n",
        "    cfg.vq_edim = int(cfg.dim_z / cfg.vq_comb_num)\n",
        "    \n",
        "    print(f\"✅ Config loaded:\")\n",
        "    print(f\"   - use_model_fusion: {cfg.use_model_fusion}\")\n",
        "    print(f\"   - max_pts_len_thresh: {cfg.max_pts_len_thresh}\")\n",
        "    print(f\"   - img_size: {cfg.img_size}\")\n",
        "    \n",
        "    # Create Google Drive dataset for aardvark category\n",
        "    gdrive_dataset = SVGDataset_GoogleDrive(\n",
        "        data_path=DATA_PATH,\n",
        "        h=224, w=224,\n",
        "        fixed_length=cfg.max_pts_len_thresh,\n",
        "        category=\"aardvark\",\n",
        "        file_list=[\"66543-200.svg\"],\n",
        "        transform=Normalize(224, 224),\n",
        "        use_model_fusion=cfg.use_model_fusion\n",
        "    )\n",
        "    \n",
        "    print(f\"✅ Google Drive Dataset created: {len(gdrive_dataset)} path samples\")\n",
        "    \n",
        "    # Create normalizer for coordinate transformation\n",
        "    normalizer = Normalize(224, 224)\n",
        "    \n",
        "    # Create test directory\n",
        "    os.makedirs(TEST_PATH, exist_ok=True)\n",
        "    \n",
        "    if len(gdrive_dataset) > 0:\n",
        "        print(f\"\\n💾 Saving {len(gdrive_dataset)} samples to {TEST_PATH}\")\n",
        "        \n",
        "        for i in range(len(gdrive_dataset)):\n",
        "            sample = gdrive_dataset[i]\n",
        "            \n",
        "            # Get sample info\n",
        "            svg_path = sample[\"filepaths\"]\n",
        "            path_idx = sample[\"path_index\"]\n",
        "            normalized_points = sample[\"points\"]  # These are normalized (0-1 range)\n",
        "            cubics = sample[\"cubics\"]\n",
        "            path_img = sample[\"path_img\"]\n",
        "            \n",
        "            print(f\"\\n📄 Processing sample {i+1}:\")\n",
        "            print(f\"   Source: {os.path.basename(svg_path)}, path {path_idx}\")\n",
        "            print(f\"   Normalized points: {normalized_points.shape}\")\n",
        "            print(f\"   Coordinate range: x[{normalized_points[:, 0].min():.3f}, {normalized_points[:, 0].max():.3f}], y[{normalized_points[:, 1].min():.3f}, {normalized_points[:, 1].max():.3f}]\")\n",
        "            \n",
        "            # 🔧 CRITICAL FIX: Apply inverse transform to get pixel coordinates\n",
        "            denormalized_points = normalizer.inverse_transform(normalized_points)\n",
        "            print(f\"   Denormalized points: {denormalized_points.shape}\")\n",
        "            print(f\"   Pixel coordinates: x[{denormalized_points[:, 0].min():.1f}, {denormalized_points[:, 0].max():.1f}], y[{denormalized_points[:, 1].min():.1f}, {denormalized_points[:, 1].max():.1f}]\")\n",
        "            \n",
        "            # 1. Save reconstructed SVG from coordinates\n",
        "            try:\n",
        "                # Use denormalized points for SVG creation\n",
        "                path_obj = pts_to_pathObj(denormalized_points)\n",
        "                \n",
        "                # Create colors for the SVG\n",
        "                device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "                fill_color = torch.tensor([0.2, 0.2, 0.8, 1.0], device=device)  # Blue fill\n",
        "                stroke_color = torch.tensor([0.0, 0.0, 0.0, 1.0], device=device)  # Black stroke\n",
        "                \n",
        "                # Save as SVG file\n",
        "                svg_output_path = f\"{TEST_PATH}/sample_{i+1}_path_{path_idx}_consistent.svg\"\n",
        "                save_paths_svg(\n",
        "                    path_list=[path_obj],\n",
        "                    fill_color_list=[fill_color],\n",
        "                    stroke_width_list=[torch.tensor(2.0)],\n",
        "                    stroke_color_list=[stroke_color],\n",
        "                    svg_path_fp=svg_output_path,\n",
        "                    canvas_height=224,\n",
        "                    canvas_width=224\n",
        "                )\n",
        "                \n",
        "                print(f\"   📁 SVG saved: {os.path.basename(svg_output_path)}\")\n",
        "                \n",
        "                # Show first few coordinates in the generated SVG\n",
        "                with open(svg_output_path, 'r') as f:\n",
        "                    svg_content = f.read()\n",
        "                path_start = svg_content.find('d=\"') + 3\n",
        "                path_end = svg_content.find('\"', path_start)\n",
        "                path_data = svg_content[path_start:path_end]\n",
        "                print(f\"   📝 Generated SVG path (first 80 chars): {path_data[:80]}...\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"   ❌ SVG save failed: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "            \n",
        "            # 2. Save rendered image (now consistent with SVG)\n",
        "            try:\n",
        "                if len(path_img) > 0 and path_img.numel() > 0:\n",
        "                    # Check tensor content\n",
        "                    print(f\"   🔍 Path image tensor: shape={path_img.shape}, min={path_img.min():.3f}, max={path_img.max():.3f}, non_zero={torch.count_nonzero(path_img)}\")\n",
        "                    \n",
        "                    # Convert tensor to PIL Image\n",
        "                    if path_img.dim() == 3:  # HWC format\n",
        "                        img_array = path_img.numpy()\n",
        "                        if img_array.shape[2] == 3:  # RGB\n",
        "                            # Normalize to 0-255 range\n",
        "                            img_array = (img_array * 255).clip(0, 255).astype('uint8')\n",
        "                            img_pil = Image.fromarray(img_array)\n",
        "                        else:  # Single channel\n",
        "                            img_array = (img_array[:,:,0] * 255).clip(0, 255).astype('uint8')\n",
        "                            img_pil = Image.fromarray(img_array, mode='L')\n",
        "                    else:\n",
        "                        # Handle other tensor formats\n",
        "                        img_array = (path_img.squeeze().numpy() * 255).clip(0, 255).astype('uint8')\n",
        "                        img_pil = Image.fromarray(img_array)\n",
        "                    \n",
        "                    # Save PNG file\n",
        "                    png_output_path = f\"{TEST_PATH}/sample_{i+1}_path_{path_idx}_consistent.png\"\n",
        "                    img_pil.save(png_output_path)\n",
        "                    \n",
        "                    print(f\"   📁 PNG saved: {os.path.basename(png_output_path)} ({img_pil.size})\")\n",
        "                    \n",
        "                else:\n",
        "                    print(f\"   ⚠️  No image data available (use_model_fusion=False)\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"   ❌ PNG save failed: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "        \n",
        "        print(f\"\\n✅ All samples saved to: {TEST_PATH}\")\n",
        "        print(f\"📊 Output files:\")\n",
        "        \n",
        "        # List saved files\n",
        "        saved_files = [f for f in os.listdir(TEST_PATH) if f.startswith('sample_') and 'consistent' in f]\n",
        "        for f in sorted(saved_files):\n",
        "            print(f\"   📄 {f}\")\n",
        "            \n",
        "    else:\n",
        "        print(\"❌ No samples found in dataset\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"❌ Sample saving failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
