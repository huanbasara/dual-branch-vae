{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "CODE_FOLDER = 'code'\n",
        "DATA_FOLDER = 'data'\n",
        "TEST_FOLDER = 'test'\n",
        "PROJECT_DIR = '/content/drive/MyDrive/Text2SVG'\n",
        "CODE_PATH = f\"{PROJECT_DIR}/{CODE_FOLDER}\"\n",
        "DATA_PATH = f\"{PROJECT_DIR}/{DATA_FOLDER}\"\n",
        "TEST_PATH = f\"{PROJECT_DIR}/{TEST_FOLDER}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Clone Code Repository\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean existing code directory and clone fresh repository\n",
        "if os.path.exists(CODE_PATH):\n",
        "    shutil.rmtree(CODE_PATH)\n",
        "\n",
        "os.chdir(PROJECT_DIR)\n",
        "result = subprocess.run(['git', 'clone', 'https://github.com/huanbasara/dual-branch-vae.git', CODE_FOLDER], \n",
        "                      capture_output=True, text=True)\n",
        "\n",
        "if result.returncode != 0:\n",
        "    raise Exception(f\"Failed to clone repository: {result.stderr}\")\n",
        "\n",
        "print(f\"‚úÖ Code repository cloned successfully to {CODE_PATH}\")\n",
        "\n",
        "# Display latest commit information\n",
        "os.chdir(CODE_PATH)\n",
        "commit_info = subprocess.run(['git', 'log', '-1', '--pretty=format:%H|%ci|%s'], \n",
        "                           capture_output=True, text=True)\n",
        "\n",
        "if commit_info.returncode == 0:\n",
        "    hash_code, commit_time, commit_msg = commit_info.stdout.strip().split('|', 2)\n",
        "    print(f\"üì¶ Latest commit:\")\n",
        "    print(f\"   Hash: {hash_code[:8]}\")\n",
        "    print(f\"   Time: {commit_time}\")\n",
        "    print(f\"   Message: {commit_msg}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Could not get commit info\")\n",
        "\n",
        "# Add code path to Python sys.path so we can import our modules\n",
        "import sys\n",
        "if CODE_PATH not in sys.path:\n",
        "    sys.path.insert(0, CODE_PATH)\n",
        "    print(f\"‚úÖ Added {CODE_PATH} to Python path\")\n",
        "else:\n",
        "    print(f\"‚úÖ {CODE_PATH} already in Python path\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install torch torchvision numpy scipy pandas scikit-learn matplotlib pillow svglib svgpathtools\n",
        "%pip install kornia opencv-python cairosvg pyyaml easydict tqdm\n",
        "# Install additional packages for SVG rendering support\n",
        "%pip install svglib reportlab cssutils\n",
        "\n",
        "# Quick module reload after code update\n",
        "import sys\n",
        "\n",
        "print(\"üîÑ Reloading modules...\")\n",
        "\n",
        "# Clear custom modules from cache\n",
        "modules_to_clear = [\n",
        "    'pydiffvg_lite', \n",
        "    'models', \n",
        "    'data', \n",
        "    'utils',\n",
        "    'pydiffvg_lite.path_utils',\n",
        "    'data.my_svg_dataset_pts'\n",
        "]\n",
        "\n",
        "for base in modules_to_clear:\n",
        "    to_remove = [m for m in sys.modules if m.startswith(base)]\n",
        "    for m in to_remove:\n",
        "        del sys.modules[m]\n",
        "\n",
        "# Re-import key modules\n",
        "import pydiffvg_lite as pydiffvg\n",
        "from models.config import _DefaultConfig  \n",
        "from models.model_pts_vae import SVGTransformer\n",
        "from data.my_svg_dataset_pts import Normalize, SVGDataset_nopadding, SVGDataset_GoogleDrive\n",
        "from utils.test_utils import pts_to_pathObj, save_paths_svg\n",
        "\n",
        "print(\"‚úÖ Modules reloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test specific SVG file: aardvark\n",
        "svg_file = f\"{DATA_PATH}/aardvark/66543-200.svg\"\n",
        "print(f\"Using test SVG: {svg_file}\")\n",
        "\n",
        "if os.path.exists(svg_file):\n",
        "    try:\n",
        "        # Test svg_to_scene function\n",
        "        canvas_width, canvas_height, shapes, shape_groups = pydiffvg_lite.svg_to_scene(svg_file)\n",
        "        \n",
        "        print(f\"‚úÖ SVG parsed successfully:\")\n",
        "        print(f\"   Canvas: {canvas_width} x {canvas_height}\")\n",
        "        print(f\"   Shapes: {len(shapes)}\")\n",
        "        print(f\"   Groups: {len(shape_groups)}\")\n",
        "        \n",
        "        # Get first shape's coordinate points\n",
        "        if len(shapes) > 0:\n",
        "            first_shape = shapes[0]\n",
        "            print(f\"   Shape type: {type(first_shape).__name__}\")\n",
        "            if hasattr(first_shape, 'points'):\n",
        "                points = first_shape.points\n",
        "                print(f\"   Points: {points.shape}\")\n",
        "                print(f\"   First points: {points[:5]}\")\n",
        "            \n",
        "        print(\"‚úÖ SVG to coordinates conversion successful!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå SVG processing failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(f\"‚ùå SVG file not found: {svg_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test VAE Model: Generate both Image and SVG outputs (Fixed)\n",
        "import torch\n",
        "import yaml\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "from models.config import _DefaultConfig\n",
        "from models.model_pts_vae import SVGTransformer\n",
        "from data.my_svg_dataset_pts import Normalize, SVGDataset_nopadding\n",
        "from utils.test_utils import pts_to_pathObj, save_paths_svg\n",
        "import pydiffvg_lite as pydiffvg\n",
        "\n",
        "print(\"üß† Testing VAE Model: Image + SVG Generation (Fixed)...\")\n",
        "\n",
        "# Use the project's test SVG file\n",
        "svg_file = f\"{CODE_PATH}/data/vae_dataset/circle_10.svg\"\n",
        "print(f\"Using test SVG: {svg_file}\")\n",
        "\n",
        "if not os.path.exists(svg_file):\n",
        "    print(f\"‚ùå SVG file not found: {svg_file}\")\n",
        "else:\n",
        "    try:\n",
        "        # 1. Load VAE model config\n",
        "        cfg = _DefaultConfig()\n",
        "        yaml_path = f\"{CODE_PATH}/configs/vae_config_cmd_10.yaml\"\n",
        "        \n",
        "        with open(yaml_path, 'r') as f:\n",
        "            config_data = yaml.safe_load(f)\n",
        "        \n",
        "        for key, value in config_data.items():\n",
        "            setattr(cfg, key, value)\n",
        "        \n",
        "        cfg.img_latent_dim = int(cfg.d_img_model / 64.0)\n",
        "        cfg.vq_edim = int(cfg.dim_z / cfg.vq_comb_num)\n",
        "        \n",
        "        print(f\"‚úÖ Config loaded:\")\n",
        "        print(f\"   use_model_fusion: {cfg.use_model_fusion}\")\n",
        "        print(f\"   img_size: {cfg.img_size}\")\n",
        "        \n",
        "        # 2. Create VAE model\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        model = SVGTransformer(cfg)\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "        print(f\"‚úÖ Model created: {type(model).__name__} on {device}\")\n",
        "        \n",
        "        # 3. Prepare dataset\n",
        "        dataset_h, dataset_w = 224, 224\n",
        "        svg_dir = f\"{CODE_PATH}/data/vae_dataset\"\n",
        "        svg_filename = \"circle_10.svg\"\n",
        "        \n",
        "        os.makedirs(TEST_PATH, exist_ok=True)\n",
        "        \n",
        "        dataset = SVGDataset_nopadding(\n",
        "            directory=svg_dir,\n",
        "            h=dataset_h, w=dataset_w,\n",
        "            fixed_length=cfg.max_pts_len_thresh,\n",
        "            file_list=[svg_filename],\n",
        "            img_dir=svg_dir,\n",
        "            transform=Normalize(dataset_w, dataset_h),\n",
        "            use_model_fusion=cfg.use_model_fusion\n",
        "        )\n",
        "        \n",
        "        loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "        print(f\"‚úÖ Dataset created: {len(dataset)} samples\")\n",
        "        \n",
        "        # 4. Run model prediction\n",
        "        for batch_data in loader:\n",
        "            # Extract model inputs\n",
        "            path_imgs = batch_data[\"path_img\"].to(device)\n",
        "            bat_s, _, _, _ = batch_data[\"cubics\"].shape\n",
        "            cubics_batch_fl = batch_data[\"cubics\"].view(bat_s, -1, 2)\n",
        "            data_pts = cubics_batch_fl.to(device)\n",
        "            data_input = data_pts.unsqueeze(1)\n",
        "            \n",
        "            print(f\"‚úÖ Input data prepared:\")\n",
        "            print(f\"   Path images: {path_imgs.shape}\")\n",
        "            print(f\"   Data points: {data_input.shape}\")\n",
        "            \n",
        "            # Forward pass\n",
        "            with torch.no_grad():\n",
        "                output = model(args_enc=data_input, args_dec=data_input, ref_img=path_imgs)\n",
        "            \n",
        "            print(f\"‚úÖ Model prediction completed\")\n",
        "            print(f\"   Output keys: {list(output.keys())}\")\n",
        "            \n",
        "            # Initialize all path variables\n",
        "            input_path = f\"{TEST_PATH}/input_image.png\"\n",
        "            rec_img_path = f\"{TEST_PATH}/reconstructed_image.png\"\n",
        "            svg_output_path = f\"{TEST_PATH}/reconstructed_shape.svg\"\n",
        "            coords_path = f\"{TEST_PATH}/coordinates.txt\"\n",
        "            \n",
        "            # 5. Save Input Image (reference)\n",
        "            if path_imgs.shape[0] > 0:\n",
        "                input_img_tensor = path_imgs[0].cpu()\n",
        "                if input_img_tensor.shape[0] == 1:  # Grayscale\n",
        "                    input_img_array = input_img_tensor.squeeze().numpy() * 255\n",
        "                    input_img = Image.fromarray(input_img_array.astype('uint8'))\n",
        "                else:  # RGB\n",
        "                    input_img_array = input_img_tensor.permute(1, 2, 0).numpy() * 255\n",
        "                    input_img = Image.fromarray(input_img_array.astype('uint8'))\n",
        "                \n",
        "                input_img.save(input_path)\n",
        "                print(f\"üìÅ Input image saved: {input_path}\")\n",
        "            \n",
        "            # 6. Save Reconstructed Image from Image Decoder\n",
        "            if \"rec_img\" in output:\n",
        "                rec_img_tensor = output[\"rec_img\"][0].cpu()\n",
        "                print(f\"   Reconstructed image shape: {rec_img_tensor.shape}\")\n",
        "                \n",
        "                if len(rec_img_tensor.shape) == 3:  # CHW format\n",
        "                    if rec_img_tensor.shape[0] == 1:  # Grayscale\n",
        "                        rec_img_array = rec_img_tensor.squeeze().numpy()\n",
        "                        rec_img_array = ((rec_img_array - rec_img_array.min()) / \n",
        "                                       (rec_img_array.max() - rec_img_array.min()) * 255)\n",
        "                        rec_img = Image.fromarray(rec_img_array.astype('uint8'))\n",
        "                    else:  # RGB\n",
        "                        rec_img_array = rec_img_tensor.permute(1, 2, 0).numpy()\n",
        "                        rec_img_array = ((rec_img_array - rec_img_array.min()) / \n",
        "                                       (rec_img_array.max() - rec_img_array.min()) * 255)\n",
        "                        rec_img = Image.fromarray(rec_img_array.astype('uint8'))\n",
        "                \n",
        "                rec_img.save(rec_img_path)\n",
        "                print(f\"üìÅ Reconstructed image saved: {rec_img_path}\")\n",
        "            \n",
        "            # 7. Convert Coordinates to SVG and Save\n",
        "            if \"args_logits\" in output:\n",
        "                generated_pts_batch = output[\"args_logits\"]\n",
        "                print(f\"   Generated coordinates shape: {generated_pts_batch.shape}\")\n",
        "                \n",
        "                # Get the first sample coordinates\n",
        "                generated_coords = generated_pts_batch[0].squeeze().cpu()\n",
        "                print(f\"   Processed coordinates shape: {generated_coords.shape}\")\n",
        "                \n",
        "                # Convert coordinates to path object\n",
        "                try:\n",
        "                    # Reshape coordinates for path creation\n",
        "                    if len(generated_coords.shape) == 2:  # [num_points, 2]\n",
        "                        convert_points = generated_coords\n",
        "                    else:\n",
        "                        convert_points = generated_coords.view(-1, 2)\n",
        "                    \n",
        "                    print(f\"   Convert points shape: {convert_points.shape}\")\n",
        "                    \n",
        "                    # Create path object\n",
        "                    path_obj = pts_to_pathObj(convert_points)\n",
        "                    print(f\"‚úÖ Path object created with {len(path_obj.points)} points\")\n",
        "                    \n",
        "                    # Create colors for the SVG\n",
        "                    fill_color = torch.tensor([0.0, 0.0, 0.0, 1.0], device=device)\n",
        "                    stroke_color = torch.tensor([0.0, 0.0, 0.0, 1.0], device=device)\n",
        "                    \n",
        "                    # Save as SVG file\n",
        "                    save_paths_svg(\n",
        "                        path_list=[path_obj],\n",
        "                        fill_color_list=[fill_color],\n",
        "                        stroke_width_list=[torch.tensor(1.0)],\n",
        "                        stroke_color_list=[stroke_color],\n",
        "                        svg_path_fp=svg_output_path,\n",
        "                        canvas_height=dataset_h,\n",
        "                        canvas_width=dataset_w\n",
        "                    )\n",
        "                    \n",
        "                    print(f\"üìÅ Reconstructed SVG saved: {svg_output_path}\")\n",
        "                    \n",
        "                    # Save coordinates as text for inspection\n",
        "                    with open(coords_path, 'w') as f:\n",
        "                        f.write(\"VAE Generated Coordinates\\n\")\n",
        "                        f.write(\"=\" * 30 + \"\\n\")\n",
        "                        f.write(f\"Shape: {generated_pts_batch.shape}\\n\")\n",
        "                        f.write(f\"Processed shape: {convert_points.shape}\\n\")\n",
        "                        f.write(\"\\nCoordinate Points:\\n\")\n",
        "                        for i, pt in enumerate(convert_points[:20]):\n",
        "                            f.write(f\"Point {i:2d}: [{pt[0]:8.3f}, {pt[1]:8.3f}]\\n\")\n",
        "                        if len(convert_points) > 20:\n",
        "                            f.write(f\"... and {len(convert_points) - 20} more points\\n\")\n",
        "                    \n",
        "                    print(f\"üìÅ Coordinates saved: {coords_path}\")\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå SVG conversion failed: {e}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "            \n",
        "            break  # Process only first batch\n",
        "        \n",
        "        print(\"‚úÖ VAE Dual Output Test Completed!\")\n",
        "        print(\"üìä Generated Files:\")\n",
        "        print(f\"   üñºÔ∏è  Input image: {input_path}\")\n",
        "        if \"rec_img\" in output:\n",
        "            print(f\"   üñºÔ∏è  Reconstructed image: {rec_img_path}\")\n",
        "        if \"args_logits\" in output:\n",
        "            print(f\"   üìÑ Reconstructed SVG: {svg_output_path}\")\n",
        "            print(f\"   üìä Coordinates data: {coords_path}\")\n",
        "        \n",
        "        print(\"\\nüéØ VAE dual-branch outputs successfully generated!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå VAE model test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Google Drive Dataset: Load aardvark SVG with multi-path support (Standalone)\n",
        "import torch\n",
        "import yaml\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "print(\"üêæ Testing Google Drive Dataset: aardvark multi-path...\")\n",
        "\n",
        "try:\n",
        "    # Load VAE config independently\n",
        "    from models.config import _DefaultConfig\n",
        "    from data.my_svg_dataset_pts import SVGDataset_GoogleDrive, Normalize\n",
        "    import pydiffvg_lite as pydiffvg\n",
        "    \n",
        "    cfg = _DefaultConfig()\n",
        "    yaml_path = f'{CODE_PATH}/configs/vae_config_cmd_10.yaml'\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        config_data = yaml.safe_load(f)\n",
        "    for key, value in config_data.items():\n",
        "        setattr(cfg, key, value)\n",
        "    cfg.img_latent_dim = int(cfg.d_img_model / 64.0)\n",
        "    cfg.vq_edim = int(cfg.dim_z / cfg.vq_comb_num)\n",
        "    \n",
        "    print(f\"‚úÖ Config loaded:\")\n",
        "    print(f\"   - use_model_fusion: {cfg.use_model_fusion}\")\n",
        "    print(f\"   - max_pts_len_thresh: {cfg.max_pts_len_thresh}\")\n",
        "    print(f\"   - img_size: {cfg.img_size}\")\n",
        "    \n",
        "    # Create Google Drive dataset for aardvark category\n",
        "    gdrive_dataset = SVGDataset_GoogleDrive(\n",
        "        data_path=DATA_PATH,\n",
        "        h=224, w=224,\n",
        "        fixed_length=cfg.max_pts_len_thresh,\n",
        "        category=\"aardvark\",\n",
        "        file_list=[\"66543-200.svg\"],\n",
        "        transform=Normalize(224, 224),\n",
        "        use_model_fusion=cfg.use_model_fusion\n",
        "    )\n",
        "    \n",
        "    gdrive_loader = DataLoader(gdrive_dataset, batch_size=1, shuffle=False)\n",
        "    print(f\"‚úÖ Google Drive Dataset created: {len(gdrive_dataset)} path samples\")\n",
        "    \n",
        "    # Test loading first sample\n",
        "    if len(gdrive_dataset) > 0:\n",
        "            # Test loading first sample\n",
        "        if len(gdrive_dataset) > 0:\n",
        "            # ========== Âú®ËøôÈáåÊ∑ªÂä†Ë∞ÉËØï‰ª£Á†Å ==========\n",
        "            print(\"\\nüîç Debug info for first sample:\")\n",
        "            svg_path, path_idx = gdrive_dataset.samples[0]\n",
        "            print(f\"SVG file: {svg_path}\")\n",
        "            print(f\"Path index: {path_idx}\")\n",
        "\n",
        "            # ÊâãÂä®ÊâßË°åËß£ÊûêËøáÁ®ãÊù•Êü•ÁúãËØ¶ÁªÜ‰ø°ÊÅØ\n",
        "            canvas_width, canvas_height, shapes, shape_groups = pydiffvg.svg_to_scene(svg_path)\n",
        "            print(f\"Original shapes count: {len(shapes)}\")\n",
        "\n",
        "            if len(shapes) > path_idx:\n",
        "                original_shape = shapes[path_idx]\n",
        "                print(f\"Original shape points: {original_shape.points.shape}\")\n",
        "                print(f\"Original num_control_points: {original_shape.num_control_points}\")\n",
        "                \n",
        "                # Ê†áÂáÜÂåñ\n",
        "                standardized_shapes = pydiffvg.standardize_svg_paths(shapes)\n",
        "                standardized_shape = standardized_shapes[path_idx]\n",
        "                print(f\"Standardized points: {standardized_shape.points.shape}\")\n",
        "                print(f\"Standardized num_control_points: {standardized_shape.num_control_points}\")\n",
        "                \n",
        "                # ËÆ°ÁÆóÊúüÊúõÂÄº\n",
        "                fixed_length = cfg.max_pts_len_thresh\n",
        "                desired_cubics_length = fixed_length // 3\n",
        "                print(f\"Expected cubics length: {desired_cubics_length}\")\n",
        "            # ========== Ë∞ÉËØï‰ª£Á†ÅÁªìÊùü ==========\n",
        "        sample = gdrive_dataset[0]\n",
        "        print(f\"‚úÖ Sample loaded successfully\")\n",
        "        print(f\"   - Points shape: {sample['points'].shape}\")\n",
        "        print(f\"   - Cubics shape: {sample['cubics'].shape}\")\n",
        "        print(f\"   - Path index: {sample['path_index']}\")\n",
        "        print(f\"   - File path: {sample['filepaths']}\")\n",
        "        \n",
        "        if len(sample['path_img']) > 0:\n",
        "            print(f\"   - Image shape: {sample['path_img'].shape}\")\n",
        "        else:\n",
        "            print(f\"   - No image rendered (use_model_fusion=False)\")\n",
        "        \n",
        "        # Show first few coordinate points\n",
        "        print(f\"   - First 3 points: {sample['points'][:3]}\")\n",
        "        \n",
        "        # Test all samples in this SVG\n",
        "        print(f\"\\nüìä All path samples from aardvark/66543-200.svg:\")\n",
        "        for i in range(len(gdrive_dataset)):\n",
        "            sample_i = gdrive_dataset[i]\n",
        "            print(f\"   Path {sample_i['path_index']}: {sample_i['points'].shape[0]} points\")\n",
        "    else:\n",
        "        print(\"‚ùå No samples found in dataset\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Google Drive Dataset test failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
