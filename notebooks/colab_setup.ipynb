{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "CODE_FOLDER = 'code'\n",
        "DATA_FOLDER = 'data'\n",
        "TEST_FOLDER = 'test'\n",
        "PROJECT_DIR = '/content/drive/MyDrive/Text2SVG'\n",
        "CODE_PATH = f\"{PROJECT_DIR}/{CODE_FOLDER}\"\n",
        "DATA_PATH = f\"{PROJECT_DIR}/{DATA_FOLDER}\"\n",
        "TEST_PATH = f\"{PROJECT_DIR}/{TEST_FOLDER}\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Clone Code Repository\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Google Drive Dataset: Save samples as SVG and PNG files (Fixed coordinates)\n",
        "import torch\n",
        "import yaml\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "print(\"üíæ Saving Google Drive Dataset samples with corrected coordinates...\")\n",
        "\n",
        "try:\n",
        "    # Load VAE config independently\n",
        "    from models.config import _DefaultConfig\n",
        "    from data.my_svg_dataset_pts import SVGDataset_GoogleDrive, Normalize\n",
        "    from utils.test_utils import pts_to_pathObj, save_paths_svg\n",
        "    import pydiffvg_lite as pydiffvg\n",
        "    \n",
        "    cfg = _DefaultConfig()\n",
        "    yaml_path = f'{CODE_PATH}/configs/vae_config_cmd_10.yaml'\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        config_data = yaml.safe_load(f)\n",
        "    for key, value in config_data.items():\n",
        "        setattr(cfg, key, value)\n",
        "    cfg.img_latent_dim = int(cfg.d_img_model / 64.0)\n",
        "    cfg.vq_edim = int(cfg.dim_z / cfg.vq_comb_num)\n",
        "    \n",
        "    print(f\"‚úÖ Config loaded:\")\n",
        "    print(f\"   - use_model_fusion: {cfg.use_model_fusion}\")\n",
        "    print(f\"   - max_pts_len_thresh: {cfg.max_pts_len_thresh}\")\n",
        "    print(f\"   - img_size: {cfg.img_size}\")\n",
        "    \n",
        "    # Create Google Drive dataset for aardvark category\n",
        "    gdrive_dataset = SVGDataset_GoogleDrive(\n",
        "        data_path=DATA_PATH,\n",
        "        h=224, w=224,\n",
        "        fixed_length=cfg.max_pts_len_thresh,\n",
        "        category=\"aardvark\",\n",
        "        file_list=[\"66543-200.svg\"],\n",
        "        transform=Normalize(224, 224),\n",
        "        use_model_fusion=cfg.use_model_fusion\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Google Drive Dataset created: {len(gdrive_dataset)} path samples\")\n",
        "    \n",
        "    # Create normalizer for coordinate transformation\n",
        "    normalizer = Normalize(224, 224)\n",
        "    \n",
        "    # Create test directory\n",
        "    os.makedirs(TEST_PATH, exist_ok=True)\n",
        "    \n",
        "    if len(gdrive_dataset) > 0:\n",
        "        print(f\"\\nüíæ Saving {len(gdrive_dataset)} samples to {TEST_PATH}\")\n",
        "        \n",
        "        for i in range(len(gdrive_dataset)):\n",
        "            sample = gdrive_dataset[i]\n",
        "            \n",
        "            # Get sample info\n",
        "            svg_path = sample[\"filepaths\"]\n",
        "            path_idx = sample[\"path_index\"]\n",
        "            normalized_points = sample[\"points\"]  # These are normalized (0-1 range)\n",
        "            cubics = sample[\"cubics\"]\n",
        "            path_img = sample[\"path_img\"]\n",
        "            \n",
        "            print(f\"\\nüìÑ Processing sample {i+1}:\")\n",
        "            print(f\"   Source: {os.path.basename(svg_path)}, path {path_idx}\")\n",
        "            print(f\"   Normalized points: {normalized_points.shape}\")\n",
        "            print(f\"   Coordinate range: x[{normalized_points[:, 0].min():.3f}, {normalized_points[:, 0].max():.3f}], y[{normalized_points[:, 1].min():.3f}, {normalized_points[:, 1].max():.3f}]\")\n",
        "            \n",
        "            # üîß CRITICAL FIX: Apply inverse transform to get pixel coordinates\n",
        "            denormalized_points = normalizer.inverse_transform(normalized_points)\n",
        "            print(f\"   Denormalized points: {denormalized_points.shape}\")\n",
        "            print(f\"   Pixel coordinates: x[{denormalized_points[:, 0].min():.1f}, {denormalized_points[:, 0].max():.1f}], y[{denormalized_points[:, 1].min():.1f}, {denormalized_points[:, 1].max():.1f}]\")\n",
        "            \n",
        "            # 1. Save reconstructed SVG from coordinates\n",
        "            try:\n",
        "                # Use denormalized points for SVG creation\n",
        "                path_obj = pts_to_pathObj(denormalized_points)\n",
        "                \n",
        "                # Create colors for the SVG\n",
        "                device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "                fill_color = torch.tensor([0.2, 0.2, 0.8, 1.0], device=device)  # Blue fill\n",
        "                stroke_color = torch.tensor([0.0, 0.0, 0.0, 1.0], device=device)  # Black stroke\n",
        "                \n",
        "                # Save as SVG file\n",
        "                svg_output_path = f\"{TEST_PATH}/sample_{i+1}_path_{path_idx}_fixed.svg\"\n",
        "                save_paths_svg(\n",
        "                    path_list=[path_obj],\n",
        "                    fill_color_list=[fill_color],\n",
        "                    stroke_width_list=[torch.tensor(2.0)],\n",
        "                    stroke_color_list=[stroke_color],\n",
        "                    svg_path_fp=svg_output_path,\n",
        "                    canvas_height=224,\n",
        "                    canvas_width=224\n",
        "                )\n",
        "                \n",
        "                print(f\"   üìÅ SVG saved: {os.path.basename(svg_output_path)}\")\n",
        "                \n",
        "                # Show first few coordinates in the generated SVG\n",
        "                with open(svg_output_path, 'r') as f:\n",
        "                    svg_content = f.read()\n",
        "                path_start = svg_content.find('d=\"') + 3\n",
        "                path_end = svg_content.find('\"', path_start)\n",
        "                path_data = svg_content[path_start:path_end]\n",
        "                print(f\"   üìù Generated SVG path (first 80 chars): {path_data[:80]}...\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ùå SVG save failed: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "            \n",
        "            # 2. Save rendered image\n",
        "            try:\n",
        "                if len(path_img) > 0 and path_img.numel() > 0:\n",
        "                    # Convert tensor to PIL Image\n",
        "                    if path_img.dim() == 3:  # HWC format\n",
        "                        img_array = path_img.numpy()\n",
        "                        if img_array.shape[2] == 3:  # RGB\n",
        "                            # Normalize to 0-255 range\n",
        "                            img_array = (img_array * 255).clip(0, 255).astype('uint8')\n",
        "                            img_pil = Image.fromarray(img_array)\n",
        "                        else:  # Single channel\n",
        "                            img_array = (img_array[:,:,0] * 255).clip(0, 255).astype('uint8')\n",
        "                            img_pil = Image.fromarray(img_array, mode='L')\n",
        "                    else:\n",
        "                        # Handle other tensor formats\n",
        "                        img_array = (path_img.squeeze().numpy() * 255).clip(0, 255).astype('uint8')\n",
        "                        img_pil = Image.fromarray(img_array)\n",
        "                    \n",
        "                    # Save PNG file\n",
        "                    png_output_path = f\"{TEST_PATH}/sample_{i+1}_path_{path_idx}_fixed.png\"\n",
        "                    img_pil.save(png_output_path)\n",
        "                    \n",
        "                    print(f\"   üìÅ PNG saved: {os.path.basename(png_output_path)} ({img_pil.size})\")\n",
        "                    \n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  No image data available (use_model_fusion=False)\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ùå PNG save failed: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "        \n",
        "        print(f\"\\n‚úÖ All samples saved to: {TEST_PATH}\")\n",
        "        print(f\"üìä Output files:\")\n",
        "        \n",
        "        # List saved files\n",
        "        saved_files = [f for f in os.listdir(TEST_PATH) if f.startswith('sample_') and 'fixed' in f]\n",
        "        for f in sorted(saved_files):\n",
        "            print(f\"   üìÑ {f}\")\n",
        "            \n",
        "    else:\n",
        "        print(\"‚ùå No samples found in dataset\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Sample saving failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install torch torchvision numpy scipy pandas scikit-learn matplotlib pillow svglib svgpathtools\n",
        "%pip install kornia opencv-python cairosvg pyyaml easydict tqdm\n",
        "# Install additional packages for SVG rendering support\n",
        "%pip install svglib reportlab cssutils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Google Drive Dataset: Save samples as SVG and PNG files (Fixed coordinates and consistency)\n",
        "import torch\n",
        "import yaml\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "print(\"üíæ Saving Google Drive Dataset samples with corrected coordinates and consistent rendering...\")\n",
        "\n",
        "try:\n",
        "    # Load VAE config independently\n",
        "    from models.config import _DefaultConfig\n",
        "    from data.my_svg_dataset_pts import SVGDataset_GoogleDrive, Normalize\n",
        "    from utils.test_utils import pts_to_pathObj, save_paths_svg\n",
        "    import pydiffvg_lite as pydiffvg\n",
        "    \n",
        "    cfg = _DefaultConfig()\n",
        "    yaml_path = f'{CODE_PATH}/configs/vae_config_cmd_10.yaml'\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        config_data = yaml.safe_load(f)\n",
        "    for key, value in config_data.items():\n",
        "        setattr(cfg, key, value)\n",
        "    cfg.img_latent_dim = int(cfg.d_img_model / 64.0)\n",
        "    cfg.vq_edim = int(cfg.dim_z / cfg.vq_comb_num)\n",
        "    \n",
        "    print(f\"‚úÖ Config loaded:\")\n",
        "    print(f\"   - use_model_fusion: {cfg.use_model_fusion}\")\n",
        "    print(f\"   - max_pts_len_thresh: {cfg.max_pts_len_thresh}\")\n",
        "    print(f\"   - img_size: {cfg.img_size}\")\n",
        "    \n",
        "    # Create Google Drive dataset for aardvark category\n",
        "    gdrive_dataset = SVGDataset_GoogleDrive(\n",
        "        data_path=DATA_PATH,\n",
        "        h=224, w=224,\n",
        "        fixed_length=cfg.max_pts_len_thresh,\n",
        "        category=\"aardvark\",\n",
        "        file_list=[\"66543-200.svg\"],\n",
        "        transform=Normalize(224, 224),\n",
        "        use_model_fusion=cfg.use_model_fusion\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Google Drive Dataset created: {len(gdrive_dataset)} path samples\")\n",
        "    \n",
        "    # Create normalizer for coordinate transformation\n",
        "    normalizer = Normalize(224, 224)\n",
        "    \n",
        "    # Create test directory\n",
        "    os.makedirs(TEST_PATH, exist_ok=True)\n",
        "    \n",
        "    if len(gdrive_dataset) > 0:\n",
        "        print(f\"\\nüíæ Saving {len(gdrive_dataset)} samples to {TEST_PATH}\")\n",
        "        \n",
        "        for i in range(len(gdrive_dataset)):\n",
        "            sample = gdrive_dataset[i]\n",
        "            \n",
        "            # Get sample info\n",
        "            svg_path = sample[\"filepaths\"]\n",
        "            path_idx = sample[\"path_index\"]\n",
        "            normalized_points = sample[\"points\"]  # These are normalized (0-1 range)\n",
        "            cubics = sample[\"cubics\"]\n",
        "            path_img = sample[\"path_img\"]\n",
        "            \n",
        "            print(f\"\\nüìÑ Processing sample {i+1}:\")\n",
        "            print(f\"   Source: {os.path.basename(svg_path)}, path {path_idx}\")\n",
        "            print(f\"   Normalized points: {normalized_points.shape}\")\n",
        "            print(f\"   Coordinate range: x[{normalized_points[:, 0].min():.3f}, {normalized_points[:, 0].max():.3f}], y[{normalized_points[:, 1].min():.3f}, {normalized_points[:, 1].max():.3f}]\")\n",
        "            \n",
        "            # üîß CRITICAL FIX: Apply inverse transform to get pixel coordinates\n",
        "            denormalized_points = normalizer.inverse_transform(normalized_points)\n",
        "            print(f\"   Denormalized points: {denormalized_points.shape}\")\n",
        "            print(f\"   Pixel coordinates: x[{denormalized_points[:, 0].min():.1f}, {denormalized_points[:, 0].max():.1f}], y[{denormalized_points[:, 1].min():.1f}, {denormalized_points[:, 1].max():.1f}]\")\n",
        "            \n",
        "            # 1. Save reconstructed SVG from coordinates\n",
        "            try:\n",
        "                # Use denormalized points for SVG creation\n",
        "                path_obj = pts_to_pathObj(denormalized_points)\n",
        "                \n",
        "                # Create colors for the SVG\n",
        "                device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "                fill_color = torch.tensor([0.2, 0.2, 0.8, 1.0], device=device)  # Blue fill\n",
        "                stroke_color = torch.tensor([0.0, 0.0, 0.0, 1.0], device=device)  # Black stroke\n",
        "                \n",
        "                # Save as SVG file\n",
        "                svg_output_path = f\"{TEST_PATH}/sample_{i+1}_path_{path_idx}_consistent.svg\"\n",
        "                save_paths_svg(\n",
        "                    path_list=[path_obj],\n",
        "                    fill_color_list=[fill_color],\n",
        "                    stroke_width_list=[torch.tensor(2.0)],\n",
        "                    stroke_color_list=[stroke_color],\n",
        "                    svg_path_fp=svg_output_path,\n",
        "                    canvas_height=224,\n",
        "                    canvas_width=224\n",
        "                )\n",
        "                \n",
        "                print(f\"   üìÅ SVG saved: {os.path.basename(svg_output_path)}\")\n",
        "                \n",
        "                # Show first few coordinates in the generated SVG\n",
        "                with open(svg_output_path, 'r') as f:\n",
        "                    svg_content = f.read()\n",
        "                path_start = svg_content.find('d=\"') + 3\n",
        "                path_end = svg_content.find('\"', path_start)\n",
        "                path_data = svg_content[path_start:path_end]\n",
        "                print(f\"   üìù Generated SVG path (first 80 chars): {path_data[:80]}...\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ùå SVG save failed: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "            \n",
        "            # 2. Save rendered image (now consistent with SVG)\n",
        "            try:\n",
        "                if len(path_img) > 0 and path_img.numel() > 0:\n",
        "                    # Check tensor content\n",
        "                    print(f\"   üîç Path image tensor: shape={path_img.shape}, min={path_img.min():.3f}, max={path_img.max():.3f}, non_zero={torch.count_nonzero(path_img)}\")\n",
        "                    \n",
        "                    # Convert tensor to PIL Image\n",
        "                    if path_img.dim() == 3:  # HWC format\n",
        "                        img_array = path_img.numpy()\n",
        "                        if img_array.shape[2] == 3:  # RGB\n",
        "                            # Normalize to 0-255 range\n",
        "                            img_array = (img_array * 255).clip(0, 255).astype('uint8')\n",
        "                            img_pil = Image.fromarray(img_array)\n",
        "                        else:  # Single channel\n",
        "                            img_array = (img_array[:,:,0] * 255).clip(0, 255).astype('uint8')\n",
        "                            img_pil = Image.fromarray(img_array, mode='L')\n",
        "                    else:\n",
        "                        # Handle other tensor formats\n",
        "                        img_array = (path_img.squeeze().numpy() * 255).clip(0, 255).astype('uint8')\n",
        "                        img_pil = Image.fromarray(img_array)\n",
        "                    \n",
        "                    # Save PNG file\n",
        "                    png_output_path = f\"{TEST_PATH}/sample_{i+1}_path_{path_idx}_consistent.png\"\n",
        "                    img_pil.save(png_output_path)\n",
        "                    \n",
        "                    print(f\"   üìÅ PNG saved: {os.path.basename(png_output_path)} ({img_pil.size})\")\n",
        "                    \n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  No image data available (use_model_fusion=False)\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ùå PNG save failed: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "        \n",
        "        print(f\"\\n‚úÖ All samples saved to: {TEST_PATH}\")\n",
        "        print(f\"üìä Output files:\")\n",
        "        \n",
        "        # List saved files\n",
        "        saved_files = [f for f in os.listdir(TEST_PATH) if f.startswith('sample_') and 'consistent' in f]\n",
        "        for f in sorted(saved_files):\n",
        "            print(f\"   üìÑ {f}\")\n",
        "            \n",
        "    else:\n",
        "        print(\"‚ùå No samples found in dataset\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Sample saving failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
