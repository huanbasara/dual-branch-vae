{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Init\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "import subprocess\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "CODE_FOLDER = 'code'\n",
        "DATA_FOLDER = 'data'\n",
        "TEST_FOLDER = 'test'\n",
        "PROJECT_DIR = '/content/drive/MyDrive/Text2SVG'\n",
        "CODE_PATH = f\"{PROJECT_DIR}/{CODE_FOLDER}\"\n",
        "DATA_PATH = f\"{PROJECT_DIR}/{DATA_FOLDER}\"\n",
        "TEST_PATH = f\"{PROJECT_DIR}/{TEST_FOLDER}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Clone Code Repository\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clean existing code directory and clone fresh repository\n",
        "if os.path.exists(CODE_PATH):\n",
        "    shutil.rmtree(CODE_PATH)\n",
        "\n",
        "os.chdir(PROJECT_DIR)\n",
        "result = subprocess.run(['git', 'clone', 'https://github.com/huanbasara/dual-branch-vae.git', CODE_FOLDER], \n",
        "                      capture_output=True, text=True)\n",
        "\n",
        "if result.returncode != 0:\n",
        "    raise Exception(f\"Failed to clone repository: {result.stderr}\")\n",
        "\n",
        "print(f\"‚úÖ Code repository cloned successfully to {CODE_PATH}\")\n",
        "\n",
        "# Display latest commit information\n",
        "os.chdir(CODE_PATH)\n",
        "commit_info = subprocess.run(['git', 'log', '-1', '--pretty=format:%H|%ci|%s'], \n",
        "                           capture_output=True, text=True)\n",
        "\n",
        "if commit_info.returncode == 0:\n",
        "    hash_code, commit_time, commit_msg = commit_info.stdout.strip().split('|', 2)\n",
        "    print(f\"üì¶ Latest commit:\")\n",
        "    print(f\"   Hash: {hash_code[:8]}\")\n",
        "    print(f\"   Time: {commit_time}\")\n",
        "    print(f\"   Message: {commit_msg}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Could not get commit info\")\n",
        "\n",
        "# Add code path to Python sys.path so we can import our modules\n",
        "import sys\n",
        "if CODE_PATH not in sys.path:\n",
        "    sys.path.insert(0, CODE_PATH)\n",
        "    print(f\"‚úÖ Added {CODE_PATH} to Python path\")\n",
        "else:\n",
        "    print(f\"‚úÖ {CODE_PATH} already in Python path\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install torch torchvision numpy scipy pandas scikit-learn matplotlib pillow svglib svgpathtools\n",
        "%pip install kornia opencv-python cairosvg pyyaml easydict tqdm\n",
        "# Install additional packages for SVG rendering support\n",
        "%pip install svglib reportlab cssutils\n",
        "\n",
        "# Quick module reload after code update\n",
        "import sys\n",
        "\n",
        "print(\"üîÑ Reloading modules...\")\n",
        "\n",
        "# Clear custom modules from cache\n",
        "modules_to_clear = [\n",
        "    'pydiffvg_lite', \n",
        "    'models', \n",
        "    'data', \n",
        "    'utils',\n",
        "    'pydiffvg_lite.path_utils',\n",
        "    'data.my_svg_dataset_pts'\n",
        "]\n",
        "\n",
        "for base in modules_to_clear:\n",
        "    to_remove = [m for m in sys.modules if m.startswith(base)]\n",
        "    for m in to_remove:\n",
        "        del sys.modules[m]\n",
        "\n",
        "# Re-import key modules\n",
        "import pydiffvg_lite as pydiffvg\n",
        "from models.config import _DefaultConfig  \n",
        "from models.model_pts_vae import SVGTransformer\n",
        "from data.my_svg_dataset_pts import Normalize, SVGDataset_nopadding, SVGDataset_GoogleDrive\n",
        "from utils.test_utils import pts_to_pathObj, save_paths_svg\n",
        "\n",
        "print(\"‚úÖ Modules reloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test specific SVG file: aardvark\n",
        "svg_file = f\"{DATA_PATH}/aardvark/66543-200.svg\"\n",
        "print(f\"Using test SVG: {svg_file}\")\n",
        "\n",
        "if os.path.exists(svg_file):\n",
        "    try:\n",
        "        # Test svg_to_scene function\n",
        "        canvas_width, canvas_height, shapes, shape_groups = pydiffvg_lite.svg_to_scene(svg_file)\n",
        "        \n",
        "        print(f\"‚úÖ SVG parsed successfully:\")\n",
        "        print(f\"   Canvas: {canvas_width} x {canvas_height}\")\n",
        "        print(f\"   Shapes: {len(shapes)}\")\n",
        "        print(f\"   Groups: {len(shape_groups)}\")\n",
        "        \n",
        "        # Get first shape's coordinate points\n",
        "        if len(shapes) > 0:\n",
        "            first_shape = shapes[0]\n",
        "            print(f\"   Shape type: {type(first_shape).__name__}\")\n",
        "            if hasattr(first_shape, 'points'):\n",
        "                points = first_shape.points\n",
        "                print(f\"   Points: {points.shape}\")\n",
        "                print(f\"   First points: {points[:5]}\")\n",
        "            \n",
        "        print(\"‚úÖ SVG to coordinates conversion successful!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå SVG processing failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "else:\n",
        "    print(f\"‚ùå SVG file not found: {svg_file}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test VAE Model: Generate both Image and SVG outputs (Fixed)\n",
        "import torch\n",
        "import yaml\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from torch.utils.data import DataLoader\n",
        "from models.config import _DefaultConfig\n",
        "from models.model_pts_vae import SVGTransformer\n",
        "from data.my_svg_dataset_pts import Normalize, SVGDataset_nopadding\n",
        "from utils.test_utils import pts_to_pathObj, save_paths_svg\n",
        "import pydiffvg_lite as pydiffvg\n",
        "\n",
        "print(\"üß† Testing VAE Model: Image + SVG Generation (Fixed)...\")\n",
        "\n",
        "# Use the project's test SVG file\n",
        "svg_file = f\"{CODE_PATH}/data/vae_dataset/circle_10.svg\"\n",
        "print(f\"Using test SVG: {svg_file}\")\n",
        "\n",
        "if not os.path.exists(svg_file):\n",
        "    print(f\"‚ùå SVG file not found: {svg_file}\")\n",
        "else:\n",
        "    try:\n",
        "        # 1. Load VAE model config\n",
        "        cfg = _DefaultConfig()\n",
        "        yaml_path = f\"{CODE_PATH}/configs/vae_config_cmd_10.yaml\"\n",
        "        \n",
        "        with open(yaml_path, 'r') as f:\n",
        "            config_data = yaml.safe_load(f)\n",
        "        \n",
        "        for key, value in config_data.items():\n",
        "            setattr(cfg, key, value)\n",
        "        \n",
        "        cfg.img_latent_dim = int(cfg.d_img_model / 64.0)\n",
        "        cfg.vq_edim = int(cfg.dim_z / cfg.vq_comb_num)\n",
        "        \n",
        "        print(f\"‚úÖ Config loaded:\")\n",
        "        print(f\"   use_model_fusion: {cfg.use_model_fusion}\")\n",
        "        print(f\"   img_size: {cfg.img_size}\")\n",
        "        \n",
        "        # 2. Create VAE model\n",
        "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "        model = SVGTransformer(cfg)\n",
        "        model = model.to(device)\n",
        "        model.eval()\n",
        "        print(f\"‚úÖ Model created: {type(model).__name__} on {device}\")\n",
        "        \n",
        "        # 3. Prepare dataset\n",
        "        dataset_h, dataset_w = 224, 224\n",
        "        svg_dir = f\"{CODE_PATH}/data/vae_dataset\"\n",
        "        svg_filename = \"circle_10.svg\"\n",
        "        \n",
        "        os.makedirs(TEST_PATH, exist_ok=True)\n",
        "        \n",
        "        dataset = SVGDataset_nopadding(\n",
        "            directory=svg_dir,\n",
        "            h=dataset_h, w=dataset_w,\n",
        "            fixed_length=cfg.max_pts_len_thresh,\n",
        "            file_list=[svg_filename],\n",
        "            img_dir=svg_dir,\n",
        "            transform=Normalize(dataset_w, dataset_h),\n",
        "            use_model_fusion=cfg.use_model_fusion\n",
        "        )\n",
        "        \n",
        "        loader = DataLoader(dataset, batch_size=1, shuffle=False)\n",
        "        print(f\"‚úÖ Dataset created: {len(dataset)} samples\")\n",
        "        \n",
        "        # 4. Run model prediction\n",
        "        for batch_data in loader:\n",
        "            # Extract model inputs\n",
        "            path_imgs = batch_data[\"path_img\"].to(device)\n",
        "            bat_s, _, _, _ = batch_data[\"cubics\"].shape\n",
        "            cubics_batch_fl = batch_data[\"cubics\"].view(bat_s, -1, 2)\n",
        "            data_pts = cubics_batch_fl.to(device)\n",
        "            data_input = data_pts.unsqueeze(1)\n",
        "            \n",
        "            print(f\"‚úÖ Input data prepared:\")\n",
        "            print(f\"   Path images: {path_imgs.shape}\")\n",
        "            print(f\"   Data points: {data_input.shape}\")\n",
        "            \n",
        "            # Forward pass\n",
        "            with torch.no_grad():\n",
        "                output = model(args_enc=data_input, args_dec=data_input, ref_img=path_imgs)\n",
        "            \n",
        "            print(f\"‚úÖ Model prediction completed\")\n",
        "            print(f\"   Output keys: {list(output.keys())}\")\n",
        "            \n",
        "            # Initialize all path variables\n",
        "            input_path = f\"{TEST_PATH}/input_image.png\"\n",
        "            rec_img_path = f\"{TEST_PATH}/reconstructed_image.png\"\n",
        "            svg_output_path = f\"{TEST_PATH}/reconstructed_shape.svg\"\n",
        "            coords_path = f\"{TEST_PATH}/coordinates.txt\"\n",
        "            \n",
        "            # 5. Save Input Image (reference)\n",
        "            if path_imgs.shape[0] > 0:\n",
        "                input_img_tensor = path_imgs[0].cpu()\n",
        "                if input_img_tensor.shape[0] == 1:  # Grayscale\n",
        "                    input_img_array = input_img_tensor.squeeze().numpy() * 255\n",
        "                    input_img = Image.fromarray(input_img_array.astype('uint8'))\n",
        "                else:  # RGB\n",
        "                    input_img_array = input_img_tensor.permute(1, 2, 0).numpy() * 255\n",
        "                    input_img = Image.fromarray(input_img_array.astype('uint8'))\n",
        "                \n",
        "                input_img.save(input_path)\n",
        "                print(f\"üìÅ Input image saved: {input_path}\")\n",
        "            \n",
        "            # 6. Save Reconstructed Image from Image Decoder\n",
        "            if \"rec_img\" in output:\n",
        "                rec_img_tensor = output[\"rec_img\"][0].cpu()\n",
        "                print(f\"   Reconstructed image shape: {rec_img_tensor.shape}\")\n",
        "                \n",
        "                if len(rec_img_tensor.shape) == 3:  # CHW format\n",
        "                    if rec_img_tensor.shape[0] == 1:  # Grayscale\n",
        "                        rec_img_array = rec_img_tensor.squeeze().numpy()\n",
        "                        rec_img_array = ((rec_img_array - rec_img_array.min()) / \n",
        "                                       (rec_img_array.max() - rec_img_array.min()) * 255)\n",
        "                        rec_img = Image.fromarray(rec_img_array.astype('uint8'))\n",
        "                    else:  # RGB\n",
        "                        rec_img_array = rec_img_tensor.permute(1, 2, 0).numpy()\n",
        "                        rec_img_array = ((rec_img_array - rec_img_array.min()) / \n",
        "                                       (rec_img_array.max() - rec_img_array.min()) * 255)\n",
        "                        rec_img = Image.fromarray(rec_img_array.astype('uint8'))\n",
        "                \n",
        "                rec_img.save(rec_img_path)\n",
        "                print(f\"üìÅ Reconstructed image saved: {rec_img_path}\")\n",
        "            \n",
        "            # 7. Convert Coordinates to SVG and Save\n",
        "            if \"args_logits\" in output:\n",
        "                generated_pts_batch = output[\"args_logits\"]\n",
        "                print(f\"   Generated coordinates shape: {generated_pts_batch.shape}\")\n",
        "                \n",
        "                # Get the first sample coordinates\n",
        "                generated_coords = generated_pts_batch[0].squeeze().cpu()\n",
        "                print(f\"   Processed coordinates shape: {generated_coords.shape}\")\n",
        "                \n",
        "                # Convert coordinates to path object\n",
        "                try:\n",
        "                    # Reshape coordinates for path creation\n",
        "                    if len(generated_coords.shape) == 2:  # [num_points, 2]\n",
        "                        convert_points = generated_coords\n",
        "                    else:\n",
        "                        convert_points = generated_coords.view(-1, 2)\n",
        "                    \n",
        "                    print(f\"   Convert points shape: {convert_points.shape}\")\n",
        "                    \n",
        "                    # Create path object\n",
        "                    path_obj = pts_to_pathObj(convert_points)\n",
        "                    print(f\"‚úÖ Path object created with {len(path_obj.points)} points\")\n",
        "                    \n",
        "                    # Create colors for the SVG\n",
        "                    fill_color = torch.tensor([0.0, 0.0, 0.0, 1.0], device=device)\n",
        "                    stroke_color = torch.tensor([0.0, 0.0, 0.0, 1.0], device=device)\n",
        "                    \n",
        "                    # Save as SVG file\n",
        "                    save_paths_svg(\n",
        "                        path_list=[path_obj],\n",
        "                        fill_color_list=[fill_color],\n",
        "                        stroke_width_list=[torch.tensor(1.0)],\n",
        "                        stroke_color_list=[stroke_color],\n",
        "                        svg_path_fp=svg_output_path,\n",
        "                        canvas_height=dataset_h,\n",
        "                        canvas_width=dataset_w\n",
        "                    )\n",
        "                    \n",
        "                    print(f\"üìÅ Reconstructed SVG saved: {svg_output_path}\")\n",
        "                    \n",
        "                    # Save coordinates as text for inspection\n",
        "                    with open(coords_path, 'w') as f:\n",
        "                        f.write(\"VAE Generated Coordinates\\n\")\n",
        "                        f.write(\"=\" * 30 + \"\\n\")\n",
        "                        f.write(f\"Shape: {generated_pts_batch.shape}\\n\")\n",
        "                        f.write(f\"Processed shape: {convert_points.shape}\\n\")\n",
        "                        f.write(\"\\nCoordinate Points:\\n\")\n",
        "                        for i, pt in enumerate(convert_points[:20]):\n",
        "                            f.write(f\"Point {i:2d}: [{pt[0]:8.3f}, {pt[1]:8.3f}]\\n\")\n",
        "                        if len(convert_points) > 20:\n",
        "                            f.write(f\"... and {len(convert_points) - 20} more points\\n\")\n",
        "                    \n",
        "                    print(f\"üìÅ Coordinates saved: {coords_path}\")\n",
        "                    \n",
        "                except Exception as e:\n",
        "                    print(f\"‚ùå SVG conversion failed: {e}\")\n",
        "                    import traceback\n",
        "                    traceback.print_exc()\n",
        "            \n",
        "            break  # Process only first batch\n",
        "        \n",
        "        print(\"‚úÖ VAE Dual Output Test Completed!\")\n",
        "        print(\"üìä Generated Files:\")\n",
        "        print(f\"   üñºÔ∏è  Input image: {input_path}\")\n",
        "        if \"rec_img\" in output:\n",
        "            print(f\"   üñºÔ∏è  Reconstructed image: {rec_img_path}\")\n",
        "        if \"args_logits\" in output:\n",
        "            print(f\"   üìÑ Reconstructed SVG: {svg_output_path}\")\n",
        "            print(f\"   üìä Coordinates data: {coords_path}\")\n",
        "        \n",
        "        print(\"\\nüéØ VAE dual-branch outputs successfully generated!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå VAE model test failed: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test Google Drive Dataset: Save samples as SVG and PNG files (Fixed coordinates)\n",
        "import torch\n",
        "import yaml\n",
        "import os\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from PIL import Image\n",
        "\n",
        "print(\"üíæ Saving Google Drive Dataset samples with corrected coordinates...\")\n",
        "\n",
        "try:\n",
        "    # Load VAE config independently\n",
        "    from models.config import _DefaultConfig\n",
        "    from data.my_svg_dataset_pts import SVGDataset_GoogleDrive, Normalize\n",
        "    from utils.test_utils import pts_to_pathObj, save_paths_svg\n",
        "    import pydiffvg_lite as pydiffvg\n",
        "    \n",
        "    cfg = _DefaultConfig()\n",
        "    yaml_path = f'{CODE_PATH}/configs/vae_config_cmd_10.yaml'\n",
        "    with open(yaml_path, 'r') as f:\n",
        "        config_data = yaml.safe_load(f)\n",
        "    for key, value in config_data.items():\n",
        "        setattr(cfg, key, value)\n",
        "    cfg.img_latent_dim = int(cfg.d_img_model / 64.0)\n",
        "    cfg.vq_edim = int(cfg.dim_z / cfg.vq_comb_num)\n",
        "    \n",
        "    print(f\"‚úÖ Config loaded:\")\n",
        "    print(f\"   - use_model_fusion: {cfg.use_model_fusion}\")\n",
        "    print(f\"   - max_pts_len_thresh: {cfg.max_pts_len_thresh}\")\n",
        "    print(f\"   - img_size: {cfg.img_size}\")\n",
        "    \n",
        "    # Create Google Drive dataset for aardvark category\n",
        "    gdrive_dataset = SVGDataset_GoogleDrive(\n",
        "        data_path=DATA_PATH,\n",
        "        h=224, w=224,\n",
        "        fixed_length=cfg.max_pts_len_thresh,\n",
        "        category=\"aardvark\",\n",
        "        file_list=[\"66543-200.svg\"],\n",
        "        transform=Normalize(224, 224),\n",
        "        use_model_fusion=cfg.use_model_fusion\n",
        "    )\n",
        "    \n",
        "    print(f\"‚úÖ Google Drive Dataset created: {len(gdrive_dataset)} path samples\")\n",
        "    \n",
        "    # Create normalizer for coordinate transformation\n",
        "    normalizer = Normalize(224, 224)\n",
        "    \n",
        "    # Create test directory\n",
        "    os.makedirs(TEST_PATH, exist_ok=True)\n",
        "    \n",
        "    if len(gdrive_dataset) > 0:\n",
        "        print(f\"\\nüíæ Saving {len(gdrive_dataset)} samples to {TEST_PATH}\")\n",
        "        \n",
        "        for i in range(len(gdrive_dataset)):\n",
        "            sample = gdrive_dataset[i]\n",
        "            \n",
        "            # Get sample info\n",
        "            svg_path = sample[\"filepaths\"]\n",
        "            path_idx = sample[\"path_index\"]\n",
        "            normalized_points = sample[\"points\"]  # These are normalized (0-1 range)\n",
        "            cubics = sample[\"cubics\"]\n",
        "            path_img = sample[\"path_img\"]\n",
        "            \n",
        "            print(f\"\\nüìÑ Processing sample {i+1}:\")\n",
        "            print(f\"   Source: {os.path.basename(svg_path)}, path {path_idx}\")\n",
        "            print(f\"   Normalized points: {normalized_points.shape}\")\n",
        "            print(f\"   Coordinate range: x[{normalized_points[:, 0].min():.3f}, {normalized_points[:, 0].max():.3f}], y[{normalized_points[:, 1].min():.3f}, {normalized_points[:, 1].max():.3f}]\")\n",
        "            \n",
        "            # üîß CRITICAL FIX: Apply inverse transform to get pixel coordinates\n",
        "            denormalized_points = normalizer.inverse_transform(normalized_points)\n",
        "            print(f\"   Denormalized points: {denormalized_points.shape}\")\n",
        "            print(f\"   Pixel coordinates: x[{denormalized_points[:, 0].min():.1f}, {denormalized_points[:, 0].max():.1f}], y[{denormalized_points[:, 1].min():.1f}, {denormalized_points[:, 1].max():.1f}]\")\n",
        "            \n",
        "            # 1. Save reconstructed SVG from coordinates\n",
        "            try:\n",
        "                # Use denormalized points for SVG creation\n",
        "                path_obj = pts_to_pathObj(denormalized_points)\n",
        "                \n",
        "                # Create colors for the SVG\n",
        "                device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "                fill_color = torch.tensor([0.2, 0.2, 0.8, 1.0], device=device)  # Blue fill\n",
        "                stroke_color = torch.tensor([0.0, 0.0, 0.0, 1.0], device=device)  # Black stroke\n",
        "                \n",
        "                # Save as SVG file\n",
        "                svg_output_path = f\"{TEST_PATH}/sample_{i+1}_path_{path_idx}_fixed.svg\"\n",
        "                save_paths_svg(\n",
        "                    path_list=[path_obj],\n",
        "                    fill_color_list=[fill_color],\n",
        "                    stroke_width_list=[torch.tensor(2.0)],\n",
        "                    stroke_color_list=[stroke_color],\n",
        "                    svg_path_fp=svg_output_path,\n",
        "                    canvas_height=224,\n",
        "                    canvas_width=224\n",
        "                )\n",
        "                \n",
        "                print(f\"   üìÅ SVG saved: {os.path.basename(svg_output_path)}\")\n",
        "                \n",
        "                # Show first few coordinates in the generated SVG\n",
        "                with open(svg_output_path, 'r') as f:\n",
        "                    svg_content = f.read()\n",
        "                path_start = svg_content.find('d=\"') + 3\n",
        "                path_end = svg_content.find('\"', path_start)\n",
        "                path_data = svg_content[path_start:path_end]\n",
        "                print(f\"   üìù Generated SVG path (first 80 chars): {path_data[:80]}...\")\n",
        "                \n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ùå SVG save failed: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "            \n",
        "            # 2. Save rendered image\n",
        "            try:\n",
        "                if len(path_img) > 0 and path_img.numel() > 0:\n",
        "                    # Convert tensor to PIL Image\n",
        "                    if path_img.dim() == 3:  # HWC format\n",
        "                        img_array = path_img.numpy()\n",
        "                        if img_array.shape[2] == 3:  # RGB\n",
        "                            # Normalize to 0-255 range\n",
        "                            img_array = (img_array * 255).clip(0, 255).astype('uint8')\n",
        "                            img_pil = Image.fromarray(img_array)\n",
        "                        else:  # Single channel\n",
        "                            img_array = (img_array[:,:,0] * 255).clip(0, 255).astype('uint8')\n",
        "                            img_pil = Image.fromarray(img_array, mode='L')\n",
        "                    else:\n",
        "                        # Handle other tensor formats\n",
        "                        img_array = (path_img.squeeze().numpy() * 255).clip(0, 255).astype('uint8')\n",
        "                        img_pil = Image.fromarray(img_array)\n",
        "                    \n",
        "                    # Save PNG file\n",
        "                    png_output_path = f\"{TEST_PATH}/sample_{i+1}_path_{path_idx}_fixed.png\"\n",
        "                    img_pil.save(png_output_path)\n",
        "                    \n",
        "                    print(f\"   üìÅ PNG saved: {os.path.basename(png_output_path)} ({img_pil.size})\")\n",
        "                    \n",
        "                else:\n",
        "                    print(f\"   ‚ö†Ô∏è  No image data available (use_model_fusion=False)\")\n",
        "                    \n",
        "            except Exception as e:\n",
        "                print(f\"   ‚ùå PNG save failed: {e}\")\n",
        "                import traceback\n",
        "                traceback.print_exc()\n",
        "        \n",
        "        print(f\"\\n‚úÖ All samples saved to: {TEST_PATH}\")\n",
        "        print(f\"üìä Output files:\")\n",
        "        \n",
        "        # List saved files\n",
        "        saved_files = [f for f in os.listdir(TEST_PATH) if f.startswith('sample_') and 'fixed' in f]\n",
        "        for f in sorted(saved_files):\n",
        "            print(f\"   üìÑ {f}\")\n",
        "            \n",
        "    else:\n",
        "        print(\"‚ùå No samples found in dataset\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Sample saving failed: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
